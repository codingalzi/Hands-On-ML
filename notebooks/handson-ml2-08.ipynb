{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8장 차원 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 차원의 저주\n",
    "\n",
    "* 차원축소를 위한 접근법\n",
    "    * 사영 기법\n",
    "    * 다양체 학습\n",
    "\n",
    "* 사영 기법 알고리즘\n",
    "    * PCA(주성분 분석)\n",
    "    * 커널 PCA\n",
    "\n",
    "* 다양체 학습 알고리즘\n",
    "    * LLE(지역 선형임베딩)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수 (파이썬 3.7 추천)\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5) \n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림 저장 위치 지정\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"dim_reduction\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 차원의 저주"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고차원 공간의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3차원을 초과하는 고차원 공간의 구조를 상상하기는 매우 어려움.\n",
    "\n",
    "* 고차원 공간의 경우 두 지점 사이의 거리가 매우 멀어질 수 있으며\n",
    "    이는 특성 수가 많은 데이터들 사이의 거리가 매우 멀어질 수 있음을 의미함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원의 저주"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 머신러닝에서 다루는 많은 문제가 수 천에서 수 백만의 특성을 가진 데이터를 다룸. \n",
    "    이는 데이터셋의 특성이 이루는 공간이 수 천에서 수 백만 차원의 공간임을 의미함.\n",
    "    \n",
    "* 수 천에서 수 백만의 차원을 갖는 데이터셋을 훈련시키는 데에 엄청난 시간과 비용이 발생함. \n",
    "\n",
    "* 또한 데이터 사이가 멀기 때문에 새로운 데이터에 대한 예측값을 계산하기 위해 많은 추정 과정을 밟아야 하며,\n",
    "    따라서 과대적합 위험도가 커지는 등 훈련이 매우 어려워짐.\n",
    "\n",
    "* 데이터 사이의 거리를 충분히 작게 만들기 위해 천문학적 크기의 데이터셋이 요구되기에 사실상 \n",
    "    해결 불가능한 문제임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 많은 실전 문제의 데이터셋의 특성들이 이루는 차원을 혁신적으로 줄일 수 있음.\n",
    "\n",
    "* 예제: MNIST 데이터셋의 경우 손글씨 이미지의 테두리 영역은 거의 항상 흰색이기에 \n",
    "    숫자 인식을 위해 아무런 역할을 하지 않음. \n",
    "    따라서 그 영역을 제외한 특성들의 차원만을 이용할 수 있음.\n",
    "    실제로 784(= 18 * 18)개의 픽셀 특성 대신에 154개의 픽셀 특성만을 사용해도\n",
    "    숫자 분류를 진행할 수 있음을 아래에서 확일할 것임.\n",
    "    \n",
    "* 차원축소: 고차원의 데이터셋을 저차원의 데이터셋으로 변환하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 장점과 단점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 차원축소를 진행하면 정보를 일부 또는 상당히 잃게 됨. \n",
    "    따라서 적절한 수의 차원으로 축소를 진행해야 하며 어느 정도로 줄이는 것이 적절한지 먼저 알아내야 함.\n",
    "    \n",
    "- 반면에 차원축소 후 훈련 속도가 보다 많이 빨라짐.\n",
    "- 또한 2, 3차원으로 줄일 경우 데이터 시각화가 가능해져서 데이터들의 패턴을 인식 가능해질 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 차원축소 기법 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 사영 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특잇값 분해를 이용한 사영 기법을 설명하기 위해 \n",
    "3차원 공간에 아래와 같이 분포된 60개의 점을 2차원으로 사영하는 예제를 이용한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch08/homl08-02a.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언급된 60개의 3차원 데이터는 아래와 같이 (60, 3) 모양의 행렬 `X`로 생성한다.\n",
    "\n",
    "__참고:__ 생성되는 데이터의 x, y 좌표는 사인, 코사인 함수를 조합하며,\n",
    "수학적으로 큰 의미는 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4)\n",
    "\n",
    "m = 60\n",
    "noise = 0.1\n",
    "\n",
    "X = np.empty((m, 3))\n",
    "\n",
    "angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
    "X[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2   # x 좌표\n",
    "X[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2                # y 좌표\n",
    "\n",
    "w1, w2 = 0.1, 0.3\n",
    "X[:, 2] = X[:, 0] * w1 + X[:, 1] * w2 + noise * np.random.randn(m)             # z 좌표 (초평면 + 잡음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA(주성분 분석)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 주성분은 데이터 샘플들의 분산을 최대로 유지하는 축을 가리키며 차원의 개수만큼 주성분이 존재한다.\n",
    "분산을 최대로 유지하는 축이 첫째 주성분이며, 이후의 축은 이전 축에 수직이면서 동시에 남은 분산을 최대한\n",
    "보존하는 축으로 지정한다. 이 과정을 차원 수 만큼의 주성분을 찾을 때까지 반복한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 차원축소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차원축소는 PCA를 통해 찾은 주성분의 일부로 구성된 초평면(하이퍼플레인hyperplane)으로 \n",
    "데이터 샘플을 사영(projection)하는 과정을 의미한다.\n",
    "\n",
    "첫째부터 $d$ 번째 까지의 주성분을 축으로 사용해서 생성되는 $d$ 차원의 공간으로 데이터셋이 사영된다. \n",
    "따라서 3차원 데이터를 2차원 공간으로 보내려면 예를 들어 아래 그림의 회색 평면을 구성하는\n",
    "두 개의 축에 해당하는 주성분을 찾아야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch08/homl08-02b.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 특잇값 분해(SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 분산에 대한 주성분은 데이터셋 행렬의 특잇값 분해(SVD, singular value decomposition)를\n",
    "이용하여 쉽게 구할 수 있다.\n",
    "사이킷런의 `PCA` 모델이 특잇값 분해를 이용하여 주성분을 바로 계산할 수 있지만 여기서는 먼저 \n",
    "특잇값 분해를 사용하여 직접 주성분을 구하는 과정을 살펴본다.\n",
    "\n",
    "__주의사항:__ 평균값(mean)이 $0$이라는 가정하에 특잇값 분해를 진행해야 하기에\n",
    "아래 코드를 먼저 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_centered = X - X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특잇값 분해의 내용은 다음과 같다.\n",
    "\n",
    "평균값이 0인 데이터셋 $X$가 주어졌을 때 아래 조건을 만족시키는 세 개의 행렬 $U$, $\\Sigma$, $V$가 존재한다. \n",
    "\n",
    "$$\n",
    "X = U\\, \\Sigma \\, V^{\\!T}\n",
    "$$\n",
    "\n",
    "- $X$: m x n 행렬\n",
    "- $U$: m x m 행렬\n",
    "- $\\Sigma$: m x n 모양의 대각행렬(diagonal matrix). \n",
    "- $V$: n x n 행렬. 윗첨자 $T$는 전치행렬을 의미함.\n",
    "\n",
    "__참고:__ [위키백과: 특잇값 분해](https://ko.wikipedia.org/wiki/%ED%8A%B9%EC%9E%87%EA%B0%92_%EB%B6%84%ED%95%B4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특잇값 분해를 진행하는 `numpy.linalg.svd()` 함수를 이용하여\n",
    "`X_centered`에 대해 특잇값 분해를 진행한 결과는 다음과 같다.\n",
    "\n",
    "- `s`: 대각행렬 $\\Sigma$에 해당하지만 대각선상에 위치한 값들만 모아 놓은 길이 3인 1차원 어레이임.\n",
    "- `Vt`: $V^{\\!T}$, 즉 행렬 $V$의 전치행렬에 해당함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, Vt = np.linalg.svd(X_centered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 행렬의 모양을 확인하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 언급한 대로 `s`는 원래 (60, 3) 모양의 대각 행렬 이어야 하지만 \n",
    "여기서는 대각선 상에 위치한 세 개의 수만 포함하고 있다.\n",
    "\n",
    "__참고:__ (60, 3) 모양의 대각선은 길이가 3이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특잇값 분해가 제대로 이루어진 것인지 아래와 같이 검증할 수 있다.\n",
    "\n",
    "__주의사항:__ 행렬의 곱셈을 진행하려면 먼저 `s`를 (60, 3) 모양의 대각 행렬로 만들어야 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.zeros(X_centered.shape)\n",
    "S[:3, :3] = np.diag(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 아래와 같이 특잇값 분해가 제대로 이루어졌음을 확인할 수 있다.\n",
    "\n",
    "__참고:__ 컴퓨터를 이용한 부동소수점 연산은 일반적으로 100% 정확하지 않다.\n",
    "따라서 약간의 오차를 감안하여 두 부동소수점 값을 비교해야 한다.\n",
    "`numpy.allclose()` 함수는 지정된 오차범위 안에서 두 부동소수점의 일치여부를 판단한다.\n",
    "보다 자세한 설명은 \n",
    "[numpy.allclose 문서](https://runebook.dev/ko/docs/numpy/reference/generated/numpy.allclose)를\n",
    "참조한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X_centered, U.dot(S).dot(Vt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주성분은 앞서 특잇값 분해로 얻은 행렬 $V$의 열 벡터에 해당한다.\n",
    "0번 열이 첫째 주성분, 1번 열이 둘째 주성분, 2번 열이 셋재 주성분 벡터이다. \n",
    "아래 그림은 첫째 주성분 벡터를 보여준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch08/homl08-02c.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫째와 둘째 주성분 벡터를 함께 그리면 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch08/homl08-02d.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2차원으로 사영하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3차원 공간의 데이터를 2차원으로 보내려면 앞서 보여준 두 개의 주성분(principal components)을 선택한 후에\n",
    "두 축에 의해 생성되는 초평면hyperplane에 사영해야 한다. \n",
    "2차원으로 사영하려면 따라서 행렬 $V$의 0번과 1번 두 개의 열을 선택한 후에\n",
    "`X_centered`를 두 개의 주성분으로 구성된 행렬과 곱한다. \n",
    "\n",
    "__주의사항:__ `Vt.T` 는 $(V^{\\!T})^{T}$, 즉 $V$를 가리킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = Vt.T[:, :2]           # 주성분 2개 선택\n",
    "\n",
    "X2D = X_centered.dot(W2)   # 데이터셋을 2차원으로 사영"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2차원에 사영된 데이터셋은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch08/homl08-03.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사영된 데이터셋을 이어서 소개하는 사이킷런의 `PCA` 모델을 이용하여 구한 값과의\n",
    "비교를 위해 잠시 기억해둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2D_using_svd = X2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사이킷런의 PCA 모델 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 특잇값 분해를 직접 활용하여 2차원으로 사영하는 과정을 \n",
    "사이킷런의 `PCA` 모델을 이용하여 간단하게 해결할 수 있다.\n",
    "\n",
    "__참고:__ 평균값을 0으로 맞추는 것도 `PCA` 모델이 알아서 처리한다. \n",
    "\n",
    "- `fit()`: 평균값을 0으로 맞춘 후 특잇값 분해를 이용하여 주성분을 찾는다.\n",
    "- `transform()`: 찾은 주성분 2개를 이용하여 2차원 공간으로 데이터셋을 사영하는 과정은 다음과 같다.\n",
    "    - 평균값을 0으로 맞춘다.\n",
    "    - 특잇값 분해로 찾은 주성분을 이용하여 2차원으로 사영한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2)   # 2차원으로 사영하는 모델\n",
    "X2D = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__참고:__ 사영된 데이터의 축별 평균은 거의 0이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.40148683e-18, 9.71445147e-18])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2D.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__주의사항:__ 사이킷런을 이용하여 PCA를 진행할 때 주성분 축이 반대 방향으로 지정되는 경우가 발생할 수 있으며\n",
    "여기서도 그런 일이 벌어졌음을 아래 코드가 알려준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X2D, X2D_using_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X2D, - X2D_using_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로 훈련된 `PCA`가 알고 있는 주성분과 앞서 특잇값 분해로 얻은 주성분이\n",
    "서로 반대방향을 가리키고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93636116, -0.29854881, -0.18465208],\n",
       "       [ 0.34027485, -0.90119108, -0.2684542 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.93636116,  0.29854881,  0.18465208],\n",
       "       [-0.34027485,  0.90119108,  0.2684542 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(pca.components_, - Vt[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 재구성 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 2차원으로 사영된 데이터를 다시 3차원으로 복원한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3D_inv = pca.inverse_transform(X2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3차원으로 복원된 데이터셋은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch08/homl08-02e.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 2차원 공간으로 사영되면서 정보손실이 있었기에 3차원으로 복원한 값과\n",
    "원래의 3차원 값 사이에 오차가 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X3D_inv, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재구성 오차(reconstruction error)는 사영 전과 \n",
    "사영 후 원래 공간으로 복원한 데이터 사이의 평균제곱오차로 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010170337792848549"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.sum(np.square(X3D_inv - X), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3차원으로 복원된 데이터셋은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"https://raw.githubusercontent.com/codingalzi/handson-ml2/master/slides/images/ch08/homl08-02.png\" width=\"500\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__참고:__ `inverse_transform()` 메서드가 내부에서는 사영할 때 사용된 행렬의 전치행렬을\n",
    "사영된 데이터셋에 곱한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3D_inv_using_svd = X2D_using_svd.dot(Vt[:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 구한 `inverse_transform()` 메서드의 결과와 비교하기 위해선 다시 데이터셋의 평균값을 빼주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02406745, 0.20932515, 0.07155422])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 `PCA` 모델의 `mean_` 속성에 동일한 값이 저장되어 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02406745, 0.20932515, 0.07155422])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.mean_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 두 값을 비교하면 다음과 같이 일치한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X3D_inv_using_svd, X3D_inv - pca.mean_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 설명 분산 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설명 분산 비율은 각 주성분의 축에 대한 데이텃셈의 분산 비율을 의미한다. \n",
    "`PCA` 객체의 `explained_variance_ratio_` 속성에 사영에 사용된 주성분별 설명 분산 비율이 저장되어 있다.\n",
    "\n",
    "- 첫째 주성분의 축에 대한 데이터셋의 분산 비율:84.25%\n",
    "- 둘째 주성분의 축에 대한 데이터셋의 분산 비율:14.63%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84248607, 0.14631839])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, 2차원으로 사영한 결과 1.1% 정도의 분산을 잃는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011195535570688975"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__참고:__ 특잇값 분해로 생성된 행렬 `s`를 이용하여 모든 주성분에 대한 \n",
    "설명 분산 비율을 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84248607, 0.14631839, 0.01119554])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(s) / np.square(s).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사영 그래프 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3차원 데이터셋을 2차원 데이터셋으로 사영한 결과를 그래프로 확인해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 아래 코드는 3차원 화살표를 그리는 함수를 정의한다. \n",
    "\n",
    "__참조:__ [Plotting a 3d cube, a sphere and a vector in Matplotlib](http://stackoverflow.com/questions/11140163)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        FancyArrowPatch.__init__(self, (0,0), (0,0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.set_positions((xs[0],ys[0]),(xs[1],ys[1]))\n",
    "        FancyArrowPatch.draw(self, renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3차원 공간에서의 2차원 평면 좌표는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = [-1.8, 1.8, -1.3, 1.3, -1.0, 1.0]\n",
    "\n",
    "x1s = np.linspace(axes[0], axes[1], 10)\n",
    "x2s = np.linspace(axes[2], axes[3], 10)\n",
    "x1, x2 = np.meshgrid(x1s, x2s)                      # x축, y축 좌표\n",
    "\n",
    "C = pca.components_\n",
    "R = C.T.dot(C)\n",
    "z = (R[0, 2] * x1 + R[1, 2] * x2) / (1 - R[2, 2])   # z축 좌표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그래프 그리기: 3D 데이터셋, 평면, 그리고 사영 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure dataset_3d_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x273.6 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3.8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 3차원 데이터 산점도 그리기: 초평면 윗쪽, 아랫쪽 데이터 구분\n",
    "X3D_above = X[X[:, 2] > X3D_inv[:, 2]]    # 초평면 윗쪽 데이터\n",
    "X3D_below = X[X[:, 2] <= X3D_inv[:, 2]]   # 초평면 아랫쪽 데이터\n",
    "\n",
    "ax.plot(X3D_above[:, 0], X3D_above[:, 1], X3D_above[:, 2], \"bo\")\n",
    "ax.plot(X3D_below[:, 0], X3D_below[:, 1], X3D_below[:, 2], \"go\", alpha=0.5)\n",
    "\n",
    "# 주성분의 축 그리기\n",
    "# np.linalg.norm(C, axis=0)\n",
    "# ax.add_artist(Arrow3D([0, C[0, 0]],[0, C[0, 1]],[0, C[0, 2]], mutation_scale=15, lw=1, arrowstyle=\"-|>\", color=\"k\"))\n",
    "# ax.add_artist(Arrow3D([0, C[1, 0]],[0, C[1, 1]],[0, C[1, 2]], mutation_scale=15, lw=1, arrowstyle=\"-|>\", color=\"k\"))\n",
    "# ax.plot([0], [0], [0], \"k.\")\n",
    "\n",
    "# 초평면 그리기\n",
    "ax.plot_surface(x1, x2, z, alpha=0.2, color=\"k\")\n",
    "\n",
    "# 초평면으로 사영된 데이터셋 그리기\n",
    "ax.plot(X3D_inv[:, 0], X3D_inv[:, 1], X3D_inv[:, 2], \"k+\")\n",
    "ax.plot(X3D_inv[:, 0], X3D_inv[:, 1], X3D_inv[:, 2], \"k.\")\n",
    "\n",
    "# 사영 과정\n",
    "for i in range(m):\n",
    "    if X[i, 2] > X3D_inv[i, 2]:\n",
    "        ax.plot([X[i][0], X3D_inv[i][0]], [X[i][1], X3D_inv[i][1]], [X[i][2], X3D_inv[i][2]], \"k-\")\n",
    "    else:\n",
    "        ax.plot([X[i][0], X3D_inv[i][0]], [X[i][1], X3D_inv[i][1]], [X[i][2], X3D_inv[i][2]], \"k-\", color=\"#505050\")\n",
    "\n",
    "# 축 레이블 표기\n",
    "ax.set_xlabel(\"$x_1$\", fontsize=18, labelpad=10)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize=18, labelpad=10)\n",
    "ax.set_zlabel(\"$x_3$\", fontsize=18, labelpad=10)\n",
    "ax.set_xlim(axes[0:2])\n",
    "ax.set_ylim(axes[2:4])\n",
    "ax.set_zlim(axes[4:6])\n",
    "\n",
    "# Note: If you are using Matplotlib 3.0.0, it has a bug and does not\n",
    "# display 3D graphs properly.\n",
    "# See https://github.com/matplotlib/matplotlib/issues/12239\n",
    "# You should upgrade to a later version. If you cannot, then you can\n",
    "# use the following workaround before displaying each 3D graph:\n",
    "# for spine in ax.spines.values():\n",
    "#     spine.set_visible(False)\n",
    "\n",
    "save_fig(\"dataset_3d_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2차원 공간으로 사영된 데이터셋 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure dataset_2d_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, aspect='equal')\n",
    "\n",
    "ax.plot(X2D[:, 0], X2D[:, 1], \"k+\")\n",
    "ax.plot(X2D[:, 0], X2D[:, 1], \"k.\")\n",
    "ax.plot([0], [0], \"ko\")\n",
    "ax.arrow(0, 0, 0, 1, head_width=0.05, length_includes_head=True, head_length=0.1, fc='k', ec='k')\n",
    "ax.arrow(0, 0, 1, 0, head_width=0.05, length_includes_head=True, head_length=0.1, fc='k', ec='k')\n",
    "ax.set_xlabel(\"$z_1$\", fontsize=18)\n",
    "ax.set_ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "ax.axis([-1.5, 1.3, -1.2, 1.2])\n",
    "ax.grid(True)\n",
    "save_fig(\"dataset_2d_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 다양체 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 롤케이크 그리기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__참고:__ 롤케이크를 영어로 스위스 롤(Swiss roll)이라 부른다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_swiss_roll\n",
    "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = [-11.5, 14, -2, 23, -12, 15]\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=t, cmap=plt.cm.hot)\n",
    "ax.view_init(10, -70)\n",
    "ax.set_xlabel(\"$x_1$\", fontsize=18)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize=18)\n",
    "ax.set_zlabel(\"$x_3$\", fontsize=18)\n",
    "ax.set_xlim(axes[0:2])\n",
    "ax.set_ylim(axes[2:4])\n",
    "ax.set_zlim(axes[4:6])\n",
    "\n",
    "save_fig(\"swiss_roll_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 롤케이크 사영하기와 펼치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=t, cmap=plt.cm.hot)\n",
    "plt.axis(axes[:4])\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$x_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(t, X[:, 1], c=t, cmap=plt.cm.hot)\n",
    "plt.axis([4, 15, axes[2], axes[3]])\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.grid(True)\n",
    "\n",
    "save_fig(\"squished_swiss_roll_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다양체 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "axes = [-11.5, 14, -2, 23, -12, 15]\n",
    "\n",
    "x2s = np.linspace(axes[2], axes[3], 10)\n",
    "x3s = np.linspace(axes[4], axes[5], 10)\n",
    "x2, x3 = np.meshgrid(x2s, x3s)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "\n",
    "positive_class = X[:, 0] > 5\n",
    "X_pos = X[positive_class]\n",
    "X_neg = X[~positive_class]\n",
    "ax.view_init(10, -70)\n",
    "ax.plot(X_neg[:, 0], X_neg[:, 1], X_neg[:, 2], \"y^\")\n",
    "ax.plot_wireframe(5, x2, x3, alpha=0.5)\n",
    "ax.plot(X_pos[:, 0], X_pos[:, 1], X_pos[:, 2], \"gs\")\n",
    "ax.set_xlabel(\"$x_1$\", fontsize=18)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize=18)\n",
    "ax.set_zlabel(\"$x_3$\", fontsize=18)\n",
    "ax.set_xlim(axes[0:2])\n",
    "ax.set_ylim(axes[2:4])\n",
    "ax.set_zlim(axes[4:6])\n",
    "\n",
    "save_fig(\"manifold_decision_boundary_plot1\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.plot(t[positive_class], X[positive_class, 1], \"gs\")\n",
    "plt.plot(t[~positive_class], X[~positive_class, 1], \"y^\")\n",
    "plt.axis([4, 15, axes[2], axes[3]])\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)\n",
    "\n",
    "save_fig(\"manifold_decision_boundary_plot2\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "\n",
    "positive_class = 2 * (t[:] - 4) > X[:, 1]\n",
    "X_pos = X[positive_class]\n",
    "X_neg = X[~positive_class]\n",
    "ax.view_init(10, -70)\n",
    "ax.plot(X_neg[:, 0], X_neg[:, 1], X_neg[:, 2], \"y^\")\n",
    "ax.plot(X_pos[:, 0], X_pos[:, 1], X_pos[:, 2], \"gs\")\n",
    "ax.set_xlabel(\"$x_1$\", fontsize=18)\n",
    "ax.set_ylabel(\"$x_2$\", fontsize=18)\n",
    "ax.set_zlabel(\"$x_3$\", fontsize=18)\n",
    "ax.set_xlim(axes[0:2])\n",
    "ax.set_ylim(axes[2:4])\n",
    "ax.set_zlim(axes[4:6])\n",
    "\n",
    "save_fig(\"manifold_decision_boundary_plot3\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "plt.plot(t[positive_class], X[positive_class, 1], \"gs\")\n",
    "plt.plot(t[~positive_class], X[~positive_class, 1], \"y^\")\n",
    "plt.plot([4, 15], [0, 22], \"b-\", linewidth=2)\n",
    "plt.axis([4, 15, axes[2], axes[3]])\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)\n",
    "\n",
    "save_fig(\"manifold_decision_boundary_plot4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분산 보존"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = np.pi / 5\n",
    "stretch = 5\n",
    "m = 200\n",
    "\n",
    "np.random.seed(3)\n",
    "X = np.random.randn(m, 2) / 10\n",
    "X = X.dot(np.array([[stretch, 0],[0, 1]])) # stretch\n",
    "X = X.dot([[np.cos(angle), np.sin(angle)], [-np.sin(angle), np.cos(angle)]]) # rotate\n",
    "\n",
    "u1 = np.array([np.cos(angle), np.sin(angle)])\n",
    "u2 = np.array([np.cos(angle - 2 * np.pi/6), np.sin(angle - 2 * np.pi/6)])\n",
    "u3 = np.array([np.cos(angle - np.pi/2), np.sin(angle - np.pi/2)])\n",
    "\n",
    "X_proj1 = X.dot(u1.reshape(-1, 1))\n",
    "X_proj2 = X.dot(u2.reshape(-1, 1))\n",
    "X_proj3 = X.dot(u3.reshape(-1, 1))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot2grid((3,2), (0, 0), rowspan=3)\n",
    "plt.plot([-1.4, 1.4], [-1.4*u1[1]/u1[0], 1.4*u1[1]/u1[0]], \"k-\", linewidth=1)\n",
    "plt.plot([-1.4, 1.4], [-1.4*u2[1]/u2[0], 1.4*u2[1]/u2[0]], \"k--\", linewidth=1)\n",
    "plt.plot([-1.4, 1.4], [-1.4*u3[1]/u3[0], 1.4*u3[1]/u3[0]], \"k:\", linewidth=2)\n",
    "plt.plot(X[:, 0], X[:, 1], \"bo\", alpha=0.5)\n",
    "plt.axis([-1.4, 1.4, -1.4, 1.4])\n",
    "plt.arrow(0, 0, u1[0], u1[1], head_width=0.1, linewidth=5, length_includes_head=True, head_length=0.1, fc='k', ec='k')\n",
    "plt.arrow(0, 0, u3[0], u3[1], head_width=0.1, linewidth=5, length_includes_head=True, head_length=0.1, fc='k', ec='k')\n",
    "plt.text(u1[0] + 0.1, u1[1] - 0.05, r\"$\\mathbf{c_1}$\", fontsize=22)\n",
    "plt.text(u3[0] + 0.1, u3[1], r\"$\\mathbf{c_2}$\", fontsize=22)\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$x_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot2grid((3,2), (0, 1))\n",
    "plt.plot([-2, 2], [0, 0], \"k-\", linewidth=1)\n",
    "plt.plot(X_proj1[:, 0], np.zeros(m), \"bo\", alpha=0.3)\n",
    "plt.gca().get_yaxis().set_ticks([])\n",
    "plt.gca().get_xaxis().set_ticklabels([])\n",
    "plt.axis([-2, 2, -1, 1])\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot2grid((3,2), (1, 1))\n",
    "plt.plot([-2, 2], [0, 0], \"k--\", linewidth=1)\n",
    "plt.plot(X_proj2[:, 0], np.zeros(m), \"bo\", alpha=0.3)\n",
    "plt.gca().get_yaxis().set_ticks([])\n",
    "plt.gca().get_xaxis().set_ticklabels([])\n",
    "plt.axis([-2, 2, -1, 1])\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot2grid((3,2), (2, 1))\n",
    "plt.plot([-2, 2], [0, 0], \"k:\", linewidth=2)\n",
    "plt.plot(X_proj3[:, 0], np.zeros(m), \"bo\", alpha=0.3)\n",
    "plt.gca().get_yaxis().set_ticks([])\n",
    "plt.axis([-2, 2, -1, 1])\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.grid(True)\n",
    "\n",
    "save_fig(\"pca_best_projection_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST 압축하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__주의사항:__ 사이킷런 0.24 버전부터 `fetch_openml()`이 `DataFrame` 또는 `Series` 객체를\n",
    "이용하여 데이터셋을 반환한다.\n",
    "이를 방지하기 위해 `as_frame=False` 옵션을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "mnist.target = mnist.target.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설명 분산 비율이 95%가 되도록 하는 차원을 확인하면 154이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설명 분산 비율과 차원과의 관계를 그래프로 그리면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(cumsum, linewidth=3)\n",
    "plt.axis([0, 400, 0, 1])\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.plot([d, d], [0, 0.95], \"k:\")\n",
    "plt.plot([0, d], [0.95, 0.95], \"k:\")\n",
    "plt.plot(d, 0.95, \"ko\")\n",
    "plt.annotate(\"Elbow\", xy=(65, 0.85), xytext=(70, 0.7),\n",
    "             arrowprops=dict(arrowstyle=\"->\"), fontsize=16)\n",
    "plt.grid(True)\n",
    "save_fig(\"explained_variance_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차원을 직접 지정하는 대신 설명 분산 비율을 지정하면\n",
    "자동으로 해당 분산 비율을 만족하는 최소 차원으로 데이터셋을 사영한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "재구성 오차는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 154)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "X_recovered = pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.sum(np.square(X_recovered - X_train), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원본 손글씨 숫자와 재구성된 숫자 이미지를 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(instances, images_per_row=5, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.subplot(121)\n",
    "plot_digits(X_train[::2100])\n",
    "plt.title(\"Original\", fontsize=16)\n",
    "plt.subplot(122)\n",
    "plot_digits(X_recovered[::2100])\n",
    "plt.title(\"Compressed\", fontsize=16)\n",
    "\n",
    "save_fig(\"mnist_compression_plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이어서 설명하는 점진전 PCA의 결과와 비교하기 위해\n",
    "PCA 기법으로 압축된 손글씨 이미지 데이터를 `X_reduced_pca` 로 기억해두자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced_pca = X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점진적 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=154)\n",
    "for X_batch in np.array_split(X_train, n_batches):\n",
    "    print(\".\", end=\"\") # not shown in the book\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "\n",
    "X_reduced = inc_pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_recovered_inc_pca = inc_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 4))\n",
    "plt.subplot(121)\n",
    "plot_digits(X_train[::2100])\n",
    "plt.subplot(122)\n",
    "plot_digits(X_recovered_inc_pca[::2100])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced_inc_pca = X_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the results of transforming MNIST using regular PCA and incremental PCA. First, the means are equal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(pca.mean_, inc_pca.mean_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the results are not exactly identical. Incremental PCA gives a very good approximate solution, but it's not perfect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(X_reduced_pca, X_reduced_inc_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `memmap()` 함수 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the `memmap()` structure and copy the MNIST data into it. This would typically be done by a first program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_mnist.data\"\n",
    "m, n = X_train.shape\n",
    "\n",
    "X_mm = np.memmap(filename, dtype='float32', mode='write', shape=(m, n))\n",
    "X_mm[:] = X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now deleting the `memmap()` object will trigger its Python finalizer, which ensures that the data is saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, another program would load the data and use it for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mm = np.memmap(filename, dtype=\"float32\", mode=\"readonly\", shape=(m, n))\n",
    "\n",
    "batch_size = m // n_batches\n",
    "inc_pca = IncrementalPCA(n_components=154, batch_size=batch_size)\n",
    "inc_pca.fit(X_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_pca = PCA(n_components=154, svd_solver=\"randomized\", random_state=42)\n",
    "X_reduced = rnd_pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시간 복잡도 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's time regular PCA against Incremental PCA and Randomized PCA, for various number of principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for n_components in (2, 10, 154):\n",
    "    print(\"n_components =\", n_components)\n",
    "    regular_pca = PCA(n_components=n_components)\n",
    "    inc_pca = IncrementalPCA(n_components=n_components, batch_size=500)\n",
    "    rnd_pca = PCA(n_components=n_components, random_state=42, svd_solver=\"randomized\")\n",
    "\n",
    "    for pca in (regular_pca, inc_pca, rnd_pca):\n",
    "        t1 = time.time()\n",
    "        pca.fit(X_train)\n",
    "        t2 = time.time()\n",
    "        print(\"    {}: {:.1f} seconds\".format(pca.__class__.__name__, t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare PCA and Randomized PCA for datasets of different sizes (number of instances):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_rpca = []\n",
    "times_pca = []\n",
    "sizes = [1000, 10000, 20000, 30000, 40000, 50000, 70000, 100000, 200000, 500000]\n",
    "for n_samples in sizes:\n",
    "    X = np.random.randn(n_samples, 5)\n",
    "    pca = PCA(n_components = 2, svd_solver=\"randomized\", random_state=42)\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_rpca.append(t2 - t1)\n",
    "    pca = PCA(n_components = 2)\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_pca.append(t2 - t1)\n",
    "\n",
    "plt.plot(sizes, times_rpca, \"b-o\", label=\"RPCA\")\n",
    "plt.plot(sizes, times_pca, \"r-s\", label=\"PCA\")\n",
    "plt.xlabel(\"n_samples\")\n",
    "plt.ylabel(\"Training time\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"PCA and Randomized PCA time complexity \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's compare their performance on datasets of 2,000 instances with various numbers of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_rpca = []\n",
    "times_pca = []\n",
    "sizes = [1000, 2000, 3000, 4000, 5000, 6000]\n",
    "for n_features in sizes:\n",
    "    X = np.random.randn(2000, n_features)\n",
    "    pca = PCA(n_components = 2, random_state=42, svd_solver=\"randomized\")\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_rpca.append(t2 - t1)\n",
    "    pca = PCA(n_components = 2)\n",
    "    t1 = time.time()\n",
    "    pca.fit(X)\n",
    "    t2 = time.time()\n",
    "    times_pca.append(t2 - t1)\n",
    "\n",
    "plt.plot(sizes, times_rpca, \"b-o\", label=\"RPCA\")\n",
    "plt.plot(sizes, times_pca, \"r-s\", label=\"PCA\")\n",
    "plt.xlabel(\"n_features\")\n",
    "plt.ylabel(\"Training time\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"PCA and Randomized PCA time complexity \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 커널 PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그림 8-10 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.04)\n",
    "X_reduced = rbf_pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "lin_pca = KernelPCA(n_components = 2, kernel=\"linear\", fit_inverse_transform=True)\n",
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433, fit_inverse_transform=True)\n",
    "sig_pca = KernelPCA(n_components = 2, kernel=\"sigmoid\", gamma=0.001, coef0=1, fit_inverse_transform=True)\n",
    "\n",
    "y = t > 6.9\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "for subplot, pca, title in ((131, lin_pca, \"Linear kernel\"), (132, rbf_pca, \"RBF kernel, $\\gamma=0.04$\"), (133, sig_pca, \"Sigmoid kernel, $\\gamma=10^{-3}, r=1$\")):\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    if subplot == 132:\n",
    "        X_reduced_rbf = X_reduced\n",
    "    \n",
    "    plt.subplot(subplot)\n",
    "    #plt.plot(X_reduced[y, 0], X_reduced[y, 1], \"gs\")\n",
    "    #plt.plot(X_reduced[~y, 0], X_reduced[~y, 1], \"y^\")\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot)\n",
    "    plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "    if subplot == 131:\n",
    "        plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "    plt.grid(True)\n",
    "\n",
    "save_fig(\"kernel_pca_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그림 8-11 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "X_inverse = rbf_pca.inverse_transform(X_reduced_rbf)\n",
    "\n",
    "ax = plt.subplot(111, projection='3d')\n",
    "ax.view_init(10, -70)\n",
    "ax.scatter(X_inverse[:, 0], X_inverse[:, 1], X_inverse[:, 2], c=t, cmap=plt.cm.hot, marker=\"x\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_zlabel(\"\")\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_zticklabels([])\n",
    "\n",
    "save_fig(\"preimage_plot\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = rbf_pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(11, 4))\n",
    "plt.subplot(132)\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot, marker=\"x\")\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "        (\"kpca\", KernelPCA(n_components=2)),\n",
    "        (\"log_reg\", LogisticRegression(solver=\"lbfgs\"))\n",
    "    ])\n",
    "\n",
    "param_grid = [{\n",
    "        \"kpca__gamma\": np.linspace(0.03, 0.05, 10),\n",
    "        \"kpca__kernel\": [\"rbf\", \"sigmoid\"]\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433,\n",
    "                    fit_inverse_transform=True)\n",
    "X_reduced = rbf_pca.fit_transform(X)\n",
    "X_preimage = rbf_pca.inverse_transform(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(X, X_preimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=10, random_state=42)\n",
    "X_reduced = lle.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Unrolled swiss roll using LLE\", fontsize=14)\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot)\n",
    "plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "plt.ylabel(\"$z_2$\", fontsize=18)\n",
    "plt.axis([-0.065, 0.055, -0.1, 0.12])\n",
    "plt.grid(True)\n",
    "\n",
    "save_fig(\"lle_unrolling_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기타 차원축소 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그림 8-13 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "mds = MDS(n_components=2, random_state=42)\n",
    "X_reduced_mds = mds.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "isomap = Isomap(n_components=2)\n",
    "X_reduced_isomap = isomap.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_reduced_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_mnist = mnist[\"data\"]\n",
    "y_mnist = mnist[\"target\"]\n",
    "lda.fit(X_mnist, y_mnist)\n",
    "X_reduced_lda = lda.transform(X_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"MDS\", \"Isomap\", \"t-SNE\"]\n",
    "\n",
    "plt.figure(figsize=(11,4))\n",
    "\n",
    "for subplot, title, X_reduced in zip((131, 132, 133), titles,\n",
    "                                     (X_reduced_mds, X_reduced_isomap, X_reduced_tsne)):\n",
    "    plt.subplot(subplot)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=t, cmap=plt.cm.hot)\n",
    "    plt.xlabel(\"$z_1$\", fontsize=18)\n",
    "    if subplot == 131:\n",
    "        plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n",
    "    plt.grid(True)\n",
    "\n",
    "save_fig(\"other_dim_reduction_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제 해법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. to 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Load the MNIST dataset (introduced in chapter 3) and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset was loaded earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist['data'][:60000]\n",
    "y_train = mnist['target'][:60000]\n",
    "\n",
    "X_test = mnist['data'][60000:]\n",
    "y_test = mnist['target'][60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Next, use PCA to reduce the dataset's dimensionality, with an explained variance ratio of 95%.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Train a new Random Forest classifier on the reduced dataset and see how long it takes. Was training much faster?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "t0 = time.time()\n",
    "rnd_clf2.fit(X_train_reduced, y_train)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh no! Training is actually more than twice slower now! How can that be? Well, as we saw in this chapter, dimensionality reduction does not always lead to faster training time: it depends on the dataset, the model and the training algorithm. See figure 8-6 (the `manifold_decision_boundary_plot*` plots above). If you try a softmax classifier instead of a random forest classifier, you will find that training time is reduced by a factor of 3 when using PCA. Actually, we will do this in a second, but first let's check the precision of the new random forest classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Next evaluate the classifier on the test set: how does it compare to the previous classifier?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "y_pred = rnd_clf2.predict(X_test_reduced)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common for performance to drop slightly when reducing dimensionality, because we do lose some useful signal in the process. However, the performance drop is rather severe in this case. So PCA really did not help: it slowed down training and reduced performance. :(\n",
    "\n",
    "Let's see if it helps when using softmax regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42)\n",
    "t0 = time.time()\n",
    "log_clf.fit(X_train, y_train)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so softmax regression takes much longer to train on this dataset than the random forest classifier, plus it performs worse on the test set. But that's not what we are interested in right now, we want to see how much PCA can help softmax regression. Let's train the softmax regression model using the reduced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf2 = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", random_state=42)\n",
    "t0 = time.time()\n",
    "log_clf2.fit(X_train_reduced, y_train)\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training took {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Reducing dimensionality led to over 2× speedup. :)  Let's check the model's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_clf2.predict(X_test_reduced)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very slight drop in performance, which might be a reasonable price to pay for a 2× speedup, depending on the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there you have it: PCA can give you a formidable speedup... but not always!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Use t-SNE to reduce the MNIST dataset down to two dimensions and plot the result using Matplotlib. You can use a scatterplot using 10 different colors to represent each image's target class.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset was loaded above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction on the full 60,000 images takes a very long time, so let's only do this on a random subset of 10,000 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "m = 10000\n",
    "idx = np.random.permutation(60000)[:m]\n",
    "\n",
    "X = mnist['data'][idx]\n",
    "y = mnist['target'][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use t-SNE to reduce dimensionality down to 2D so we can plot the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_reduced = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use Matplotlib's `scatter()` function to plot a scatterplot, using a different color for each digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,10))\n",
    "plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y, cmap=\"jet\")\n",
    "plt.axis('off')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isn't this just beautiful? :) This plot tells us which numbers are easily distinguishable from the others (e.g., 0s, 6s, and most 8s are rather well separated clusters), and it also tells us which numbers are often hard to distinguish (e.g., 4s and 9s, 5s and 3s, and so on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on digits 3 and 5, which seem to overlap a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "cmap = mpl.cm.get_cmap(\"jet\")\n",
    "for digit in (2, 3, 5):\n",
    "    plt.scatter(X_reduced[y == digit, 0], X_reduced[y == digit, 1], c=[cmap(digit / 9)])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can produce a nicer image by running t-SNE on these 3 digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (y == 2) | (y == 3) | (y == 5) \n",
    "X_subset = X[idx]\n",
    "y_subset = y[idx]\n",
    "\n",
    "tsne_subset = TSNE(n_components=2, random_state=42)\n",
    "X_subset_reduced = tsne_subset.fit_transform(X_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "for digit in (2, 3, 5):\n",
    "    plt.scatter(X_subset_reduced[y_subset == digit, 0], X_subset_reduced[y_subset == digit, 1], c=[cmap(digit / 9)])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, now the clusters have far less overlap. But some 3s are all over the place. Plus, there are two distinct clusters of 2s, and also two distinct clusters of 5s. It would be nice if we could visualize a few digits from each cluster, to understand why this is the case. Let's do that now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Alternatively, you can write colored digits at the location of each instance, or even plot scaled-down versions of the digit images themselves (if you plot all digits, the visualization will be too cluttered, so you should either draw a random sample or plot an instance only if no other instance has already been plotted at a close distance). You should get a nice visualization with well-separated clusters of digits.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `plot_digits()` function that will draw a scatterplot (similar to the above scatterplots) plus write colored digits, with a minimum distance guaranteed between these digits. If the digit images are provided, they are plotted instead. This implementation was inspired from one of Scikit-Learn's excellent examples ([plot_lle_digits](http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html), based on a different digit dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
    "\n",
    "def plot_digits(X, y, min_distance=0.05, images=None, figsize=(13, 10)):\n",
    "    # Let's scale the input features so that they range from 0 to 1\n",
    "    X_normalized = MinMaxScaler().fit_transform(X)\n",
    "    # Now we create the list of coordinates of the digits plotted so far.\n",
    "    # We pretend that one is already plotted far away at the start, to\n",
    "    # avoid `if` statements in the loop below\n",
    "    neighbors = np.array([[10., 10.]])\n",
    "    # The rest should be self-explanatory\n",
    "    plt.figure(figsize=figsize)\n",
    "    cmap = mpl.cm.get_cmap(\"jet\")\n",
    "    digits = np.unique(y)\n",
    "    for digit in digits:\n",
    "        plt.scatter(X_normalized[y == digit, 0], X_normalized[y == digit, 1], c=[cmap(digit / 9)])\n",
    "    plt.axis(\"off\")\n",
    "    ax = plt.gcf().gca()  # get current axes in current figure\n",
    "    for index, image_coord in enumerate(X_normalized):\n",
    "        closest_distance = np.linalg.norm(np.array(neighbors) - image_coord, axis=1).min()\n",
    "        if closest_distance > min_distance:\n",
    "            neighbors = np.r_[neighbors, [image_coord]]\n",
    "            if images is None:\n",
    "                plt.text(image_coord[0], image_coord[1], str(int(y[index])),\n",
    "                         color=cmap(y[index] / 9), fontdict={\"weight\": \"bold\", \"size\": 16})\n",
    "            else:\n",
    "                image = images[index].reshape(28, 28)\n",
    "                imagebox = AnnotationBbox(OffsetImage(image, cmap=\"binary\"), image_coord)\n",
    "                ax.add_artist(imagebox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it! First let's just write colored digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_reduced, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's okay, but not that beautiful. Let's try with the digit images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_reduced, y, images=X, figsize=(35, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_digits(X_subset_reduced, y_subset, images=X_subset, figsize=(22, 22))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Exercise: Try using other dimensionality reduction algorithms such as PCA, LLE, or MDS and compare the resulting visualizations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with PCA. We will also time how long it takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "X_pca_reduced = PCA(n_components=2, random_state=42).fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"PCA took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_pca_reduced, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, PCA is blazingly fast! But although we do see a few clusters, there's way too much overlap. Let's try LLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "t0 = time.time()\n",
    "X_lle_reduced = LocallyLinearEmbedding(n_components=2, random_state=42).fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"LLE took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_lle_reduced, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took a while, and the result does not look too good. Let's see what happens if we apply PCA first, preserving 95% of the variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca_lle = Pipeline([\n",
    "    (\"pca\", PCA(n_components=0.95, random_state=42)),\n",
    "    (\"lle\", LocallyLinearEmbedding(n_components=2, random_state=42)),\n",
    "])\n",
    "t0 = time.time()\n",
    "X_pca_lle_reduced = pca_lle.fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"PCA+LLE took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_pca_lle_reduced, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is more or less the same, but this time it was almost 4× faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try MDS. It's much too long if we run it on 10,000 instances, so let's just try 2,000 for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "m = 2000\n",
    "t0 = time.time()\n",
    "X_mds_reduced = MDS(n_components=2, random_state=42).fit_transform(X[:m])\n",
    "t1 = time.time()\n",
    "print(\"MDS took {:.1f}s (on just 2,000 MNIST images instead of 10,000).\".format(t1 - t0))\n",
    "plot_digits(X_mds_reduced, y[:m])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meh. This does not look great, all clusters overlap too much. Let's try with PCA first, perhaps it will be faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca_mds = Pipeline([\n",
    "    (\"pca\", PCA(n_components=0.95, random_state=42)),\n",
    "    (\"mds\", MDS(n_components=2, random_state=42)),\n",
    "])\n",
    "t0 = time.time()\n",
    "X_pca_mds_reduced = pca_mds.fit_transform(X[:2000])\n",
    "t1 = time.time()\n",
    "print(\"PCA+MDS took {:.1f}s (on 2,000 MNIST images).\".format(t1 - t0))\n",
    "plot_digits(X_pca_mds_reduced, y[:2000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same result, and no speedup: PCA did not help (or hurt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try LDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "t0 = time.time()\n",
    "X_lda_reduced = LinearDiscriminantAnalysis(n_components=2).fit_transform(X, y)\n",
    "t1 = time.time()\n",
    "print(\"LDA took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_lda_reduced, y, figsize=(12,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is very fast, and it looks nice at first, until you realize that several clusters overlap severely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it's pretty clear that t-SNE won this little competition, wouldn't you agree? We did not time it, so let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "t0 = time.time()\n",
    "X_tsne_reduced = TSNE(n_components=2, random_state=42).fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"t-SNE took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_tsne_reduced, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's twice slower than LLE, but still much faster than MDS, and the result looks great. Let's see if a bit of PCA can speed it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_tsne = Pipeline([\n",
    "    (\"pca\", PCA(n_components=0.95, random_state=42)),\n",
    "    (\"tsne\", TSNE(n_components=2, random_state=42)),\n",
    "])\n",
    "t0 = time.time()\n",
    "X_pca_tsne_reduced = pca_tsne.fit_transform(X)\n",
    "t1 = time.time()\n",
    "print(\"PCA+t-SNE took {:.1f}s.\".format(t1 - t0))\n",
    "plot_digits(X_pca_tsne_reduced, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, PCA roughly gave us over 2x speedup, without damaging the result. We have a winner!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
